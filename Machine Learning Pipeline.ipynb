{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ec55dfd",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a245831",
   "metadata": {},
   "source": [
    "### 1. Importing libraries and loading data from data base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2a934e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c01dc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import datetime\n",
    "import collections\n",
    "import copy\n",
    "\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0722d5b",
   "metadata": {},
   "source": [
    "### Optional display settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fb6bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-dark')\n",
    "pd.set_option(\"display.max_rows\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d131f5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///Pipeline_Project.db')\n",
    "df = pd.read_sql_table('Messages', engine)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659a5259",
   "metadata": {},
   "source": [
    "### General division into labels and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e63cbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 1]\n",
    "Y = df.iloc[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451b22f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Weights adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a5060e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class_weights = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb059f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"for feature in Y:\n",
    "    dictionary = {(Y[feature].value_counts()/len(Y)).index[0]: (Y[feature].value_counts()/len(Y)).values[1],\n",
    "                  (Y[feature].value_counts()/len(Y)).index[1]: (Y[feature].value_counts()/len(Y)).values[0]}\n",
    "\n",
    "    class_weights.append(dictionary)\n",
    "\"\"\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1386bc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"for dictionary in copy.copy(class_weights):\n",
    "    dictionary = {k: dictionary[k] for k in sorted(dictionary)}\n",
    "    \n",
    "    class_weights.pop(0)\n",
    "    class_weights.append(dictionary)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b4d916",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for element in class_weights:\n",
    "    for key, value in element.items():\n",
    "        print(type(key), type(value))\n",
    "        \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a96720f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute_sample_weight(class_weights, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d470655",
   "metadata": {},
   "source": [
    "### 2. Key functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1675f7",
   "metadata": {},
   "source": [
    "#### Tokenizer for processing the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7ad225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    #Normalization - lowercase  - no punctuation removal - the nltk.tokenize should interpret them by itself\n",
    "    text = text.lower()\n",
    "    ######text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text)\n",
    "    #Toeknization\n",
    "    ######words = text.split()\n",
    "    words = word_tokenize(text)\n",
    "    #Stop words removal\n",
    "    words = [w for w in words if w not in stopwords.words(\"english\")]\n",
    "    \n",
    "    #Named Entities??\n",
    "    # Perhaps\n",
    "    \n",
    "    #Lemmatization\n",
    "    lemmed = [WordNetLemmatizer().lemmatize(w) for w in words]\n",
    "    \n",
    "    \n",
    "    return lemmed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88684e11",
   "metadata": {},
   "source": [
    "#### Since I want to test out many models, it seems reasonable to write a function which will make pipeline with keyword arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180c5c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sklearn_pipeline(Pipeline = Pipeline, memory = None, verbose = False, **kwargs):\n",
    "    \"\"\"\n",
    "    Firt argument is sklearn Pipepline class. It should not be changed.\n",
    "    \n",
    "    Definition of pipeline steps happens EXPLICITLY within the instantiation!\n",
    "    Definition of typical pipeline looks like following:\n",
    "    example_pipeline = make_sklearn_pipeline(steps = [('name#1',function#1),\n",
    "                                                      ('name#2',function#2),\n",
    "                                                      ('name#3',function#3),\n",
    "                                                      ('name#4',function#4)....], verbose = ...,\n",
    "                                                      memory = ...)\n",
    "    \n",
    "    It is not required to give values for ´verbose´ and ´memory´. They have default values as False\n",
    "    and None respectively. For more information visit: \n",
    "    ´https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html´\n",
    "    \"\"\"\n",
    "    pipeline = Pipeline(steps = kwargs['steps'], memory = memory, verbose = verbose)\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cff7dc",
   "metadata": {},
   "source": [
    "#### Function transforming the classification report into data frame with recall, precision and accuracy only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c383ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_from_sklearn_cl_reports(cl_reports):\n",
    "\n",
    "    data_frame = pd.DataFrame()\n",
    "\n",
    "    for feature in list(cl_reports.keys()):\n",
    "        l = cl_reports[feature].split(' ')\n",
    "        l = [x for x in l if x !='']\n",
    "        l = [x for x in l if '\\n' not in x]\n",
    "        l = l[:l.index('accuracy')]\n",
    "        columns = l[:3]\n",
    "        l = [x for x in l if x not in columns]\n",
    "        labels = []\n",
    "        precisions = []\n",
    "        recalls = []\n",
    "        f1_scores = []\n",
    "    \n",
    "        for i, element in enumerate(l):\n",
    "            if i == 0 or i % 4 == 0:\n",
    "                labels.append(element)\n",
    "                precisions.append(l[i+1])\n",
    "                recalls.append(l[i+2])\n",
    "                f1_scores.append(l[i+3])\n",
    "            \n",
    "        comunicates = [feature]*len(labels)\n",
    "    \n",
    "        if data_frame.shape[0] == 0:      \n",
    "            data_frame['communicate'] = comunicates\n",
    "            data_frame['label'] = labels\n",
    "            data_frame['precisions'] = precisions\n",
    "            data_frame['recalls'] = recalls\n",
    "            data_frame['f1_scores'] = f1_scores\n",
    "        \n",
    "        else:\n",
    "            auxiliary_df = pd.DataFrame()\n",
    "            auxiliary_df['communicate'] = comunicates\n",
    "            auxiliary_df['label'] = labels\n",
    "            auxiliary_df['precisions'] = precisions\n",
    "            auxiliary_df['recalls'] = recalls\n",
    "            auxiliary_df['f1_scores'] = f1_scores \n",
    "        \n",
    "            data_frame = pd.concat([data_frame, auxiliary_df])\n",
    "        \n",
    "            del auxiliary_df\n",
    "    \n",
    "    data_frame.set_index([\"communicate\"], inplace = True)\n",
    "    \n",
    "    #Chaning the data types\n",
    "    data_frame.label = data_frame.label.astype(\"float\")\n",
    "    data_frame.label = data_frame.label.astype(\"int\")\n",
    "    data_frame.precisions = data_frame.precisions.astype(\"float\")\n",
    "    data_frame.recalls = data_frame.recalls.astype(\"float\")\n",
    "    data_frame.f1_scores = data_frame.f1_scores.astype(\"float\")\n",
    "    \n",
    "    return data_frame    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77da1454",
   "metadata": {},
   "source": [
    "### 3. Building a machine learning pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe2b481",
   "metadata": {},
   "source": [
    "#### 3.1 AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35496fa4",
   "metadata": {},
   "source": [
    "##### Definition and fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98f767c",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_with_transformer = make_sklearn_pipeline(verbose = True, steps = [('vect', CountVectorizer(tokenizer = tokenize)),\n",
    "                           ('tfidf', TfidfTransformer()),                                              \n",
    "                           ('clf', MultiOutputClassifier(estimator = AdaBoostClassifier(\n",
    "                           DecisionTreeClassifier(class_weight = \"balanced\"))))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7dfd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570c4642",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_with_transformer.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a420a5",
   "metadata": {},
   "source": [
    "##### Predicting and classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55abd85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ada = adaboost_with_transformer.predict(X_test)\n",
    "y_pred_ada = pd.DataFrame(y_pred_ada, columns = list(Y.columns))\n",
    "y_test = y_test.reset_index(drop = True)\n",
    "for i, var in enumerate(Y):\n",
    "    print(var)\n",
    "    print(classification_report(y_test.iloc[:,i], y_pred_ada.iloc[:,i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8724d3a7",
   "metadata": {},
   "source": [
    "##### Providing a data frame for easier results assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810eb856",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_reports = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323f7924",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, var in enumerate(Y):\n",
    "    classification_reports[var] = (classification_report(y_test.iloc[:,i], y_pred_ada.iloc[:,i]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33deb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_with_transformer_report_df = df_from_sklearn_cl_reports(classification_reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8e5144",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_with_transformer_report_df.loc[\n",
    "    adaboost_with_transformer_report_df.label == 1].groupby(\n",
    "    [\"communicate\"])[\"precisions\"].mean().sort_values(ascending = False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd94b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_with_transformer_report_df.loc[\n",
    "    adaboost_with_transformer_report_df.label == 1].groupby(\n",
    "    [\"communicate\"])[\"recalls\"].mean().sort_values(ascending = False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f304a326",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aceff42b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7ed8f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06c05e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1ac868",
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForest_with_transformer = make_sklearn_pipeline(verbose = True, steps = [('vect', CountVectorizer(tokenizer = tokenize)),\n",
    "                           ('tfidf', TfidfTransformer()),                                              \n",
    "                           ('clf', MultiOutputClassifier(estimator = RandomForestClassifier\n",
    "                                                         (class_weight = \"balanced\")))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28ef66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForest_with_transformer.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d390062",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_forest = RandomForest_with_transformer.predict(X_test)\n",
    "y_pred_forest = pd.DataFrame(y_pred_forest, columns = list(Y.columns))\n",
    "y_test = y_test.reset_index(drop = True)\n",
    "for i, var in enumerate(Y):\n",
    "    print(var)\n",
    "    print(classification_report(y_test.iloc[:,i], y_pred_forest.iloc[:,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056c3bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_reports.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec38fcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, var in enumerate(Y):\n",
    "    classification_reports[var] = (classification_report(y_test.iloc[:,i], y_pred_forest.iloc[:,i]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a45b28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_with_transformer_report_df = df_from_sklearn_cl_reports(classification_reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e2fc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_with_transformer_report_df.loc[\n",
    "    forest_with_transformer_report_df.label == 1].groupby(\n",
    "    [\"communicate\"])[\"precisions\"].mean().sort_values(ascending = False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09119450",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_with_transformer_report_df.loc[\n",
    "    forest_with_transformer_report_df.label == 1].groupby(\n",
    "    [\"communicate\"])[\"recalls\"].mean().sort_values(ascending = False).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68746bea",
   "metadata": {},
   "source": [
    "##### Trying to ehence the model's performance via GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b1eadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'clf__estimator__n_estimators': [100,1000]    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b123dbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForest_optimized = GridSearchCV(RandomForest_with_transformer, param_grid = parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0807a981",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attention! This cell may take a bit time to perform (around 15 minutes on typical PC)\n",
    "RandomForest_optimized.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64b556c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_opt = RandomForest_optimized.predict(X_test)\n",
    "y_pred_opt = pd.DataFrame(y_pred_opt, columns = list(Y.columns))\n",
    "y_test = y_test.reset_index(drop = True)\n",
    "for i, var in enumerate(Y):\n",
    "    print(var)\n",
    "    print(classification_report(y_test.iloc[:,i], y_pred_opt.iloc[:,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b8553c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_reports.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9eea6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, var in enumerate(Y):\n",
    "    classification_reports[var] = (classification_report(y_test.iloc[:,i], y_pred_opt.iloc[:,i]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4c223d",
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForest_optimized_report_df = df_from_sklearn_cl_reports(classification_reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f2b5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForest_optimized_report_df.loc[\n",
    "    RandomForest_optimized_report_df.label == 1].groupby(\n",
    "    [\"communicate\"])[\"precisions\"].mean().sort_values(ascending = False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dc54dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForest_optimized_report_df.loc[\n",
    "    RandomForest_optimized_report_df.label == 1].groupby(\n",
    "    [\"communicate\"])[\"recalls\"].mean().sort_values(ascending = False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3829b709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e220d901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4534ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_reports.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59962a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_depth_2 = DecisionTreeClassifier(max_depth=2, min_samples_leaf=1, class_weight = \"balanced\")\n",
    "dt_depth_9 = DecisionTreeClassifier(max_depth=9, min_samples_leaf=1, class_weight = \"balanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3b1730",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'clf__estimator__base_estimator': [dt_depth_2,dt_depth_9],\n",
    "    'clf__estimator__n_estimators': [50,100]    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15841a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_transf_optimized = GridSearchCV(adaboost_with_transformer, param_grid = parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe6e9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attention! This cell may take a bit time to perform (around 15 minutes on typical PC)\n",
    "adaboost_transf_optimized.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c4f18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_opt_ada = adaboost_transf_optimized.predict(X_test)\n",
    "y_pred_opt_ada = pd.DataFrame(y_pred_opt_ada, columns = list(Y.columns))\n",
    "y_test = y_test.reset_index(drop = True)\n",
    "for i, var in enumerate(Y):\n",
    "    print(var)\n",
    "    print(classification_report(y_test.iloc[:,i], y_pred_opt_ada.iloc[:,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57bab06",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, var in enumerate(Y):\n",
    "    classification_reports[var] = (classification_report(y_test.iloc[:,i], y_pred_opt_ada.iloc[:,i]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7bc50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_optimized_report_df = df_from_sklearn_cl_reports(classification_reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b0f653",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_optimized_report_df.loc[\n",
    "    adaboost_optimized_report_df.label == 1].groupby(\n",
    "    [\"communicate\"])[\"precisions\"].mean().sort_values(ascending = False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6525aa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_optimized_report_df.loc[\n",
    "    adaboost_optimized_report_df.label == 1].groupby(\n",
    "    [\"communicate\"])[\"recalls\"].mean().sort_values(ascending = False).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93278f6c",
   "metadata": {},
   "source": [
    ">Undersampling still gives poor results - escpecially for recall which is very important in disaster response system. Undersampling may not necesserilly work good in multioutput problems, because of possible noise beeing added to the data set.\n",
    "Moreover, if we really want to balance all of the classes via undersampling we will end up with very small data set (some imbalanced classes are much less numerous than the better balanced ones). Hence the next iterration will be conducted with **´class weights´** adjustments and without any reduction of the data set size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce71f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_optimized_report_df.to_csv(\"Adaboost_DT_GridSearch_depth2and9_estimators_50and100.csv\", \n",
    "                                    index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5a95f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c8d103",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
